{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from feature_engine.selection import SelectByInformationValue\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "# import eli5\n",
    "\n",
    "class FeatureSelector:\n",
    "    # For Classification problem\n",
    "    def __init__(self):\n",
    "        self.mi = None\n",
    "        self.fisher = None\n",
    "        self.chi = None\n",
    "        self.iv = None\n",
    "        self.shap = None\n",
    "        # self.eli5 = None\n",
    "\n",
    "    def mutual_information(self, X, y):\n",
    "        mi = mutual_info_classif(X, y)\n",
    "        mi_series = pd.Series(mi, index=X.columns, name=\"Mutual Information\")\n",
    "        mi_series = mi_series.sort_values(ascending=False)\n",
    "        return mi_series\n",
    "\n",
    "    def chi_square(self, X, y):\n",
    "        chi, _ = chi2(X, y)\n",
    "        chi_series = pd.Series(chi, index=X.columns, name=\"Chi-Square\")\n",
    "        chi_series = chi_series.sort_values(ascending=False)\n",
    "        return chi_series\n",
    "\n",
    "    def fisher_score(self, X, y):\n",
    "        F, _ = f_classif(X, y)\n",
    "        fisher_score_series = pd.Series(F, index=X.columns, name=\"Fisher Score\")\n",
    "        fisher_score_series = fisher_score_series.sort_values(ascending=False)\n",
    "        return fisher_score_series\n",
    "\n",
    "    def information_value(self, X, y):\n",
    "        iv = SelectByInformationValue()\n",
    "        iv.fit(X, y)\n",
    "        iv_series = pd.Series(iv.information_values_, index=X.columns, name=\"Information Value\")\n",
    "        iv_series = iv_series.sort_values(ascending=False)\n",
    "        return iv_series\n",
    "\n",
    "    def FI_with_shap(self, X, y):\n",
    "        categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "        train_pool = Pool(X, y, cat_features = categorical_features)\n",
    "        if isinstance(y, np.ndarray) and np.issubdtype(y.dtype, np.number):\n",
    "            estimator = CatBoostRegressor(iterations=500, max_depth=5, learning_rate=0.05, random_seed=1066, logging_level='Silent')\n",
    "        else:\n",
    "            estimator = CatBoostClassifier(iterations=500, max_depth=5, learning_rate=0.05, random_seed=1066, logging_level='Silent')\n",
    "        model = estimator.fit(train_pool)   \n",
    "        shap_series = pd.Series(model.get_feature_importance(train_pool,), X.columns)\n",
    "        return shap_series\n",
    "    \n",
    "    \n",
    "    # def FI_with_eli5(self, X, y):\n",
    "    #     categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "    #     train_pool = Pool(X, y, cat_features = categorical_features)\n",
    "    #     if isinstance(y, np.ndarray) and np.issubdtype(y.dtype, np.number):\n",
    "    #         estimator = CatBoostRegressor(iterations=500, max_depth=5, learning_rate=0.05, random_seed=1066, logging_level='Silent')\n",
    "    #     else:\n",
    "    #         estimator = CatBoostClassifier(iterations=500, max_depth=5, learning_rate=0.05, random_seed=1066, logging_level='Silent')\n",
    "    #     model = estimator.fit(train_pool)\n",
    "    #     Series = eli5.explain_weights_catboost(catb = model,\n",
    "    #                  pool = train_pool,\n",
    "    #                  )\n",
    "    #     Series_ = eli5.formatters.as_dataframe.format_as_dataframe(Series)\n",
    "    #     eli5_series = pd.Series(data=Series_['weight'].values, index=Series_['feature'])\n",
    "    #     eli5_series.name = None\n",
    "    #     eli5_series.index.name = None\n",
    "    #     return eli5_series\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print(\"Calculating Fisher Score for numerical features...\")\n",
    "        # Separate numerical and categorical features\n",
    "        numerical_features = X.select_dtypes(include=[np.number])\n",
    "        categorical_features = X.select_dtypes(exclude=[np.number])\n",
    "\n",
    "        if not numerical_features.empty:\n",
    "            self.fisher = self.fisher_score(numerical_features, y)\n",
    "        else:\n",
    "            self.fisher = pd.Series([], name=\"Fisher Score\")\n",
    "\n",
    "        if not categorical_features.empty:\n",
    "            print(\"Calculating Mutual Information and Chi-Square for categorical features...\")\n",
    "            # Encode categorical variables\n",
    "            X_encoded = categorical_features.apply(LabelEncoder().fit_transform)\n",
    "            self.mi = self.mutual_information(X_encoded, y)\n",
    "            self.chi = self.chi_square(X_encoded, y)\n",
    "        else:\n",
    "            self.mi = pd.Series([], name=\"Mutual Information\")\n",
    "            self.chi = pd.Series([], name=\"Chi-Square\")\n",
    "\n",
    "        # Calculate Information Value\n",
    "        self.iv = self.information_value(X, y)\n",
    "        # Calculate Shap Value\n",
    "        self.shap = self.FI_with_shap(X, y)\n",
    "        # Calculate Shap Value\n",
    "        # self.eli5 = self.FI_with_eli5(X, y)\n",
    "\n",
    "        # Creating a DataFrame to compile all results\n",
    "        results = pd.DataFrame(index=X.columns)\n",
    "        results['Fisher Score'] = self.fisher\n",
    "        results['Mutual Information'] = self.mi\n",
    "        results['Chi-Square'] = self.chi\n",
    "        results['Information Value'] = self.iv\n",
    "        results['Shap Value'] = self.shap\n",
    "        results['Eli5 Value'] = self.eli5\n",
    "\n",
    "\n",
    "        # Ranking features based on each method\n",
    "        results['Fisher Rank'] = results['Fisher Score'].rank(ascending=False, method='min')\n",
    "        results['MI Rank'] = results['Mutual Information'].rank(ascending=False, method='min')\n",
    "        results['Chi Rank'] = results['Chi-Square'].rank(ascending=False, method='min')\n",
    "        results['IV Rank'] = results['Information Value'].rank(ascending=False, method='min')\n",
    "        results['Shap Rank'] = results['Shap Value'].rank(ascending=False, method='min')\n",
    "        # results['Eli5 Rank'] = results['Eli5 Value'].rank(ascending=False, method='min')\n",
    "\n",
    "        # Aggregating the ranks to get a combined rank\n",
    "        results['Average Rank'] = results[['Fisher Rank', 'MI Rank', 'Chi Rank', 'IV Rank', 'Shap Rank', \n",
    "                                           # 'Eli5 Rank'\n",
    "                                          ]].mean(axis=1)\n",
    "        results = results.sort_values('Average Rank')\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Fisher Score for numerical features...\n",
      "Calculating Mutual Information and Chi-Square for categorical features...\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\feature_engine\\encoding\\woe.py:67: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  pos = y.groupby(X[variable]).sum() / total_pos\n",
      "C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\feature_engine\\encoding\\woe.py:68: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  neg = inverse_y.groupby(X[variable]).sum() / total_neg\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\pasul\\AppData\\Local\\Temp\\ipykernel_12024\\383751245.py\", line 22, in <module>\n",
      "    ranking_df = selector.fit(X, y)\n",
      "  File \"C:\\Users\\pasul\\AppData\\Local\\Temp\\ipykernel_12024\\3038067178.py\", line 97, in fit\n",
      "    self.shap = self.FI_with_shap(X, y)\n",
      "  File \"C:\\Users\\pasul\\AppData\\Local\\Temp\\ipykernel_12024\\3038067178.py\", line 46, in FI_with_shap\n",
      "    train_pool = Pool(X, y, cat_features = categorical_features)\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\catboost\\core.py\", line 790, in __init__\n",
      "    self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\catboost\\core.py\", line 1411, in _init\n",
      "    self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n",
      "  File \"_catboost.pyx\", line 3941, in _catboost._PoolBase._init_pool\n",
      "  File \"_catboost.pyx\", line 3991, in _catboost._PoolBase._init_pool\n",
      "  File \"_catboost.pyx\", line 3807, in _catboost._PoolBase._init_features_order_layout_pool\n",
      "  File \"_catboost.pyx\", line 2717, in _catboost._set_features_order_data_pd_data_frame\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\pandas\\core\\generic.py\", line 6299, in __getattr__\n",
      "    return object.__getattribute__(self, name)\n",
      "AttributeError: 'DataFrame' object has no attribute 'iteritems'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2120, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1063, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1155, in get_records\n",
      "    FrameInfo(\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 780, in __init__\n",
      "    ix = inspect.getsourcelines(frame)\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\inspect.py\", line 1006, in getsourcelines\n",
      "    lines, lnum = findsource(object)\n",
      "  File \"C:\\Users\\pasul\\.conda\\envs\\myenv2\\lib\\inspect.py\", line 835, in findsource\n",
      "    raise OSError('could not get source code')\n",
      "OSError: could not get source code\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset\n",
    "data = pd.DataFrame({\n",
    "    'feature1': np.random.choice(['A', 'B', 'C'], 100),\n",
    "    'feature2': np.random.choice(['X', 'Y', 'Z'], 100),\n",
    "    'feature3': np.random.rand(100),\n",
    "    'feature4': np.random.rand(100),\n",
    "    'target': np.random.randint(0, 2, 100)\n",
    "})\n",
    "\n",
    "# Convert categorical features to category dtype\n",
    "data['feature1'] = data['feature1'].astype('category')\n",
    "data['feature2'] = data['feature2'].astype('category')\n",
    "\n",
    "X = data.drop(columns=['target'])\n",
    "y = data['target']\n",
    "\n",
    "# Initialize and fit the feature selector\n",
    "selector = FeatureSelector()\n",
    "ranking_df = selector.fit(X, y)\n",
    "ranking_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eli5.formatters.as_dataframe.format_as_dataframe()\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor, Pool\n",
    "import catboost\n",
    "estimator = CatBoostClassifier(iterations=500, max_depth=5, learning_rate=0.05, random_seed=1066, logging_level='Silent')\n",
    "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "train_pool = Pool(X, y, cat_features = categorical_features)\n",
    "\n",
    "estimator.fit(train_pool)\n",
    "\n",
    "shap_values = estimator.get_feature_importance(\n",
    "                        data=train_pool,\n",
    "                       reference_data=None,\n",
    "                       type=catboost.EFstrType.ShapValues,\n",
    "                       prettified=True,\n",
    "                       thread_count=-1,\n",
    "                       verbose=False,\n",
    "                       )\n",
    "\n",
    "shap_values,  np.abs(shap_values).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "perm_importance = permutation_importance(estimator, X, y, n_repeats=10, random_state=1066)\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "sorted_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(sorted_idx)), perm_importance.importances_mean[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(X.columns)[sorted_idx])\n",
    "plt.title('Permutation Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Skipping shap as it is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[0;32m      2\u001b[0m estimator \u001b[38;5;241m=\u001b[39m CatBoostClassifier(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, random_seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1066\u001b[39m, logging_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSilent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mselect_dtypes(exclude\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'shap'"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "estimator = CatBoostClassifier(iterations=500, max_depth=5, learning_rate=0.05, random_seed=1066, logging_level='Silent')\n",
    "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "train_pool = Pool(X, y, cat_features = categorical_features)\n",
    "estimator.fit(train_pool)\n",
    "explainer = shap.Explainer(estimator)\n",
    "shap_values = explainer(X)\n",
    "shap_importance = shap_values.abs.mean(0).values\n",
    "sorted_idx = shap_importance.argsort()\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.barh(range(len(sorted_idx)), shap_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(X.columns)[sorted_idx])\n",
    "plt.title('SHAP Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "shap.TreeExplainer(RandomForestRegressor(max_depth=4, n_estimators=10).fit(\n",
    "    np.random.normal(size=(30, 6)), np.random.normal(size=(30,))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.19.3\n",
      "  Downloading numpy-1.19.3-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Collecting shap==0.36\n",
      "  Downloading shap-0.36.0-cp38-cp38-win_amd64.whl (370 kB)\n",
      "Requirement already satisfied: pandas in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from shap==0.36) (1.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from shap==0.36) (1.2.2)\n",
      "Requirement already satisfied: tqdm>4.25.0 in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from shap==0.36) (4.66.1)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from shap==0.36) (1.7.3)\n",
      "Collecting numba\n",
      "  Using cached numba-0.58.1-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Collecting slicer\n",
      "  Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from tqdm>4.25.0->shap==0.36) (0.4.4)\n",
      "Collecting numba\n",
      "  Downloading numba-0.58.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "  Downloading numba-0.57.1-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
      "Collecting numba\n",
      "  Downloading numba-0.57.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "  Downloading numba-0.56.4-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0\n",
      "Note: you may need to restart the kernel to use updated packages.  Downloading llvmlite-0.39.1-cp38-cp38-win_amd64.whl (23.2 MB)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from numba->shap==0.36) (58.0.4)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from importlib-metadata->numba->shap==0.36) (3.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from pandas->shap==0.36) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from pandas->shap==0.36) (2020.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.7.3->pandas->shap==0.36) (1.15.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution - (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'c:\\\\programdata\\\\miniconda3\\\\envs\\\\myenv\\\\lib\\\\site-packages\\\\numpy-1.21.5.dist-info\\\\direct_url.json'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -umpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -mpy (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn->shap==0.36) (3.5.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\programdata\\miniconda3\\envs\\myenv\\lib\\site-packages (from scikit-learn->shap==0.36) (1.3.2)\n",
      "Installing collected packages: numpy, llvmlite, importlib-metadata, slicer, numba, shap\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.19.3 shap==0.36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall pyzmq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pyzmq==19.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
